%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Welcome to Overleaf --- just edit your LaTeX on the left,
% and we'll compile it for you on the right. If you open the
% 'Share' menu, you can invite other users to edit at the same
% time. See www.overleaf.com/learn for more info. Enjoy!
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Inbuilt themes in beamer
\documentclass{beamer}

% Theme choice:
\usetheme{CambridgeUS}
\usepackage{amsmath}
\providecommand{\pr}[1]{\ensuremath{\Pr\left(#1\right)}}
\providecommand{\cdf}[2]{\ensuremath{\text{F}_{#1}\left(#2\right)}}
% Title page details: 
\title{Assignment 13} 
\author{Gautam Singh (CS21BTECH11018)}
\date{\today}

\begin{document}

% Title page frame
\begin{frame}
    \titlepage 
\end{frame}

% Outline frame
\begin{frame}{Outline}
    \tableofcontents
\end{frame}

\section{Problem}
\begin{frame}{Problem Statement}
	\textbf{(Papoulis/Pillai, Exercise 5-48)} The random variable $X$ is $N(0; \sigma^2)$.
	\begin{enumerate}
		\item Using characteristic functions, show that if $g(x)$ is a function such that $g(x)\exp{(-\frac{x^2}{2\sigma^2})} \to 0$ as $|x| \to \infty$, then (Price's Theorem)
			\begin{align}
				\frac{dE\{g(X)\}}{dv} = \frac{1}{2}E\left\{\frac{d^2g(X)}{dX^2}\right\} 
				\label{eq:price}
			\end{align}
		\item The moments $\mu_n$ of $X$ are functions of $v$. Using \eqref{eq:price}, show that
			\begin{align}
				\mu_n(v) = \frac{n(n - 1)}{2}\int_{0}^{v}\mu_{n - 2}(\beta)d\beta
				\label{eq:moments}
			\end{align}
	\end{enumerate}
	Here, $v = \sigma^2$.
\end{frame}

\section{Solution}
\begin{frame}{Solution}
	\begin{alertblock}{PMF and Characteristic Function of $X$}
		Since $X \sim N(\mu; \sigma^2)$, the PMF of $X$ is given by
		\begin{align}
			f(x) = \frac{1}{\sqrt{2\pi}\sigma}\exp{\left(-\frac{(x - \mu)^2}{2\sigma^2}\right)}
			\label{eq:gauss-pmf}
		\end{align}
		The characteristic function of $X$ is given by
		\begin{align}
			\phi_X(\omega) &= E[\exp{(-j\omega X)}] = \int_{-\infty}^{\infty}\frac{1}{\sqrt{2\pi}\sigma}e^{-j\omega x}e^{-\frac{(x - \mu)^2}{2\sigma^2}}dx \\
			&= \exp{(j\mu\omega + \frac{(\sigma j\omega)^2}{2})}\int_{-\infty}^{\infty}\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x - (\mu + \sigma^2 j\omega))^2}{2\sigma^2}}dx \\
			&= \exp{(j\mu\omega + \frac{(\sigma j\omega)^2}{2})}
			\label{eq:char}
		\end{align}
	\end{alertblock}
\end{frame}
			
\begin{frame}
	\begin{alertblock}{Inverse Transform of $X$}
		The inverse transform of $f(x)$ is given by
		\begin{align}
			f(x) = \frac{1}{2\pi}\int_{-\infty}^{\infty}\phi_X(\omega)e^{-j\omega x}d\omega
			\label{eq:inv}
		\end{align}
			Here, $f(x)$ and $\phi_X(\omega)$ form a Fourier transform pair.
	\end{alertblock}
	To prove the first part, using \eqref{eq:char} and \eqref{eq:inv}, and noting that $\mu = 0$,
	\begin{align}
		\frac{dE\{g(X)\}}{dv} &= \frac{d}{dv}\int_{-\infty}^{\infty}g(x)\left(\frac{1}{2\pi}\int_{-\infty}^{\infty}\phi_X(\omega)e^{-j\omega x}d\omega\right)dx \\
		&= \int_{-\infty}^{\infty}g(x)\left(\frac{1}{2\pi}\int_{-\infty}^{\infty}\left(\frac{\partial}{\partial v}\phi_X(\omega)\right)e^{-j\omega x}d\omega\right)dx \\
		&= \int_{-\infty}^{\infty}g(x)\left(\frac{1}{2\pi}\int_{-\infty}^{\infty}\left(-\frac{\omega^2}{2}\right)\phi_X(\omega)e^{-j\omega x}d\omega\right)dx
		\label{eq:lhs-diff}
	\end{align}
\end{frame}

\begin{frame}
	We can rewrite \eqref{eq:lhs-diff} using \eqref{eq:inv} as
	\begin{align}
		\frac{dE\{g(X)\}}{dv} &= \frac{1}{2}\int_{-\infty}^{\infty}g(x)\left(\frac{1}{2\pi}\int_{-\infty}^{\infty}(-j\omega)^2\phi_X(\omega)e^{-j\omega x}d\omega\right)dx \\
		&= \frac{1}{2}\int_{-\infty}^{\infty}g(x)\frac{\partial^2f(x)}{\partial x^2}dx
		\label{eq:rhs-diff}
	\end{align}

	\noindent We assume that $g^{(k)}(x)\exp{(-\frac{x^2}{2\sigma^2})} \to 0$ as $|x| \to \infty$ for $k = 0, 1, 2$. Repeatedly integrating \eqref{eq:rhs-diff} by parts gives
	\begin{align}
		\frac{dE\{g(X)\}}{dv} &= \frac{1}{2}\int_{-\infty}^{\infty}g\frac{\partial^2f}{\partial x^2}dx \\
		&= \frac{1}{2}g\frac{\partial f}{\partial x}\Big|_{-\infty}^{\infty} - \int_{-\infty}^{\infty}\frac{\partial g}{\partial x}\frac{\partial f}{\partial x}dx \\
		&= \frac{1}{2}\int_{-\infty}^{\infty}\frac{\partial^2g}{\partial x^2}fdx - \frac{\partial g}{\partial x}f\Big|_{-\infty}^{\infty} = \frac{1}{2}E\left\{\frac{d^2g(X)}{dX^2}\right\} 
		\label{eq:sol1}
	\end{align}
\end{frame}

\begin{frame}
	For the second part, observe that $\mu_n = E[X^n]$ and hence it is a function of $v$. Further, using the exponential power series, note that for any positive integer $n$,
	\begin{align}
		\exp{\left(\frac{x^2}{2\sigma^2}\right)} &> \frac{x^{2n}}{(2\sigma^2)^nn!} \\
		\implies 0 < \frac{x^n}{\exp{\left(\frac{x^2}{2\sigma^2}\right)}} &< \frac{(2\sigma^2)^nn!}{x^n}
		\label{eq:sandwich}
	\end{align}
	and using the Sandwich Theorem, we can choose $g(x) = x^n$ to use in \eqref{eq:price}.
	\begin{align}
		\mu_n'(v) = \frac{1}{2}E\left\{n(n - 1)x^{n - 2}\right\} = \frac{n(n - 1)}{2}\mu_{n - 2}{(v)}
		\label{eq:de}
	\end{align}
	However, note that if $v = 0$, then from \eqref{eq:gauss-pmf}, $x = 0$ and consequently $\mu_n(0) = 0$. Integrating \eqref{eq:de} and changing variables, we get
	\begin{align}
		\mu_n(v) = \frac{n(n - 1)}{2}\int_{0}^{v}\mu_{n - 2}(\beta)d\beta
		\label{eq:sol2}
	\end{align}
\end{frame}

\end{document}
